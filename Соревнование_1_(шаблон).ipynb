{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeVfFuN/DeVfFuN/blob/main/%D0%A1%D0%BE%D1%80%D0%B5%D0%B2%D0%BD%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_1_(%D1%88%D0%B0%D0%B1%D0%BB%D0%BE%D0%BD).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка окружения для соревнования"
      ],
      "metadata": {
        "id": "kMrwgsm17Ucs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime kaggle --quiet\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njty2vJ97Hy7",
        "outputId": "37d26244-71c6-45d1-a8f8-907e8034bf93"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 3.42 s (started: 2024-12-13 17:03:57 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ8kfxLD70kk",
        "outputId": "6a4a51c1-a0a1-492f-d197-5dffef58f431"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.28 ms (started: 2024-12-13 17:04:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Optionally, you can dowload the data right here, if you have Kaggle api token (kaggle.json)\n",
        "\n",
        "# Upload your token\n",
        "# from google.colab import files\n",
        "# files.upload()\n",
        "\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# ! kaggle competitions download -c are-they-alive\n",
        "# ! unzip -q /content/are-they-alive.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_lZU7PWixTV",
        "outputId": "6df3c663-883f-4a55-a57f-edfe9eaf1c19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 344 µs (started: 2024-12-13 13:15:54 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FynsrYkcIJt8",
        "outputId": "02180840-8125-465c-cbd0-39ec00e97cfd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "time: 3.16 s (started: 2024-12-13 17:04:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ВАШЕ РЕШЕНИЕ\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "L4fHIZgLkNLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных"
      ],
      "metadata": {
        "id": "n-Nz8X2e64_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_dir = \"/content/train_dataset\"\n",
        "test_dataset_dir = \"/content/test_dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT35-2vdM3Nt",
        "outputId": "18b2c191-10e4-4c3b-a2d6-8cbbf0765aa2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 729 µs (started: 2024-12-13 17:04:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import csv\n",
        "\n",
        "# Define transformations\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the train dataset\n",
        "train_dataset = ImageFolder(root=train_dataset_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "print(f\"Loaded train dataset with {len(train_dataset)} samples\")\n",
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNa9uHCb7cPN",
        "outputId": "22664002-ce4b-44e1-a0de-6be521387a30"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded train dataset with 5000 samples\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.5843, 0.4471, 0.3059],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6784, 0.5529, 0.4392],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6941, 0.5765, 0.4902],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.5843, 0.5098, 0.4118],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.5922, 0.5373, 0.4706],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6000, 0.5647, 0.5255]],\n",
              " \n",
              "         [[0.0000, 0.0000, 0.0000,  ..., 0.5882, 0.4471, 0.3059],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6863, 0.5608, 0.4431],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.7020, 0.5843, 0.4941],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6000, 0.5216, 0.4235],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6078, 0.5529, 0.4824],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6157, 0.5804, 0.5373]],\n",
              " \n",
              "         [[0.0000, 0.0000, 0.0000,  ..., 0.5922, 0.4627, 0.3176],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6902, 0.5686, 0.4549],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.7020, 0.5882, 0.5059],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.5882, 0.5137, 0.4157],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.5961, 0.5412, 0.4745],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6078, 0.5725, 0.5294]]]),\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 64 ms (started: 2024-12-13 17:04:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.transform = transform\n",
        "        self.images = list(self.root_dir.glob('*'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        image = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_path.name\n",
        "\n",
        "# Define the transformation to be applied to the images\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create a custom dataset from the folder containing the images\n",
        "test_dataset = CustomImageDataset(root_dir=test_dataset_dir, transform=transform)\n",
        "\n",
        "# Create a dataloader to load the images in batches\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Loaded test dataset with {len(test_dataset)} samples\")\n",
        "\n",
        "test_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKliTQ42QlUJ",
        "outputId": "4bb00c10-fcf0-4fa0-e634-c3c8df420fd8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded test dataset with 5000 samples\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.9098, 0.9059, 0.9020,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.9176, 0.9137, 0.9098,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.9255, 0.9255, 0.9216,  ..., 0.0118, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.7059, 0.7176, 0.6980,  ..., 0.6706, 0.6706, 0.6745],\n",
              "          [0.6902, 0.6941, 0.6824,  ..., 0.6706, 0.6667, 0.6549],\n",
              "          [0.6667, 0.6706, 0.6627,  ..., 0.6078, 0.5451, 0.4824]],\n",
              " \n",
              "         [[0.9686, 0.9647, 0.9647,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.9725, 0.9725, 0.9686,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.9804, 0.9804, 0.9765,  ..., 0.0118, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.5961, 0.6353, 0.6353,  ..., 0.6510, 0.6510, 0.6549],\n",
              "          [0.5804, 0.6118, 0.6235,  ..., 0.6510, 0.6471, 0.6353],\n",
              "          [0.5569, 0.5843, 0.6078,  ..., 0.5882, 0.5294, 0.4667]],\n",
              " \n",
              "         [[0.9804, 0.9804, 0.9804,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.9804, 0.9804, 0.9804,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.9843, 0.9843, 0.9843,  ..., 0.0118, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.4000, 0.4392, 0.4549,  ..., 0.6392, 0.6392, 0.6431],\n",
              "          [0.3804, 0.4078, 0.4235,  ..., 0.6392, 0.6353, 0.6235],\n",
              "          [0.3529, 0.3804, 0.3961,  ..., 0.5804, 0.5176, 0.4588]]]),\n",
              " 'test_image_4275.png')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 26.1 ms (started: 2024-12-13 17:04:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Инициализация модели"
      ],
      "metadata": {
        "id": "EbSRIt4s8KbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LiveNonLiveClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LiveNonLiveClassifier, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(8 * 8 * 64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pitJVWwfM8Qn",
        "outputId": "7c9090c2-687b-4999-c8e2-d0187db38c32"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.74 ms (started: 2024-12-13 17:04:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images, labels.float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs.squeeze(), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMqm0VwaNEfs",
        "outputId": "ed5269c7-d8ed-41ca-aae9-6e7d04010f90"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.09 ms (started: 2024-12-13 17:04:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model = LiveNonLiveClassifier()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    print(\"Training the model...\")\n",
        "    train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYpwBnKeNUGo",
        "outputId": "e565a74e-247f-4eb5-8dc7-1623b34879f7"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Epoch [1/10], Loss: 0.5658\n",
            "Epoch [2/10], Loss: 0.4317\n",
            "Epoch [3/10], Loss: 0.4160\n",
            "Epoch [4/10], Loss: 0.3950\n",
            "Epoch [5/10], Loss: 0.3872\n",
            "Epoch [6/10], Loss: 0.3610\n",
            "Epoch [7/10], Loss: 0.3500\n",
            "Epoch [8/10], Loss: 0.3430\n",
            "Epoch [9/10], Loss: 0.3225\n",
            "Epoch [10/10], Loss: 0.3197\n",
            "time: 3min 30s (started: 2024-12-13 17:05:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def evaluate_model(model, test_loader, output_csv_path):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with open(output_csv_path, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"image_name\", \"label\"])\n",
        "            for images, image_paths in test_loader:  # Changed 'labels' to 'image_paths'\n",
        "                images = images\n",
        "                outputs = model(images)\n",
        "                predicted = (outputs.squeeze() > 0.5).int()\n",
        "\n",
        "                for i, path in enumerate(image_paths):\n",
        "                    writer.writerow([path, 1 if predicted[i].item() == 1 else 0])\n",
        "\n",
        "# Example usage:\n",
        "evaluate_model(model, test_loader, 'predictions.csv')\n"
      ],
      "metadata": {
        "outputId": "5cf438f7-579e-46ba-c837-8ed26600944f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTiQkNR__ghw"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.6 s (started: 2024-12-13 17:09:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating the model...\")\n",
        "evaluate_model(model, test_loader, r'C:\\Users\\vital\\predictions.csv')\n",
        "files.download('/content/predictions.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "E7OR09mfQuqz",
        "outputId": "913a677a-d11c-412c-fdfb-b09e145bd5e9"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac86d25d-3471-4362-b946-d902b9516700\", \"predictions.csv\", 113908)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.49 s (started: 2024-12-13 15:40:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters in the network: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn--6chVRuoW",
        "outputId": "f06ec0db-107a-4ce1-ebfe-17c4f1f4bc00"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the network: 548129\n",
            "time: 903 µs (started: 2024-12-13 14:05:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение модели и все остальное"
      ],
      "metadata": {
        "id": "AC7wRqptSJVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do everything you need to get the best result here"
      ],
      "metadata": {
        "id": "pr3Imvy2SU6R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}